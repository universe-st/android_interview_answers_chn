# ConcurrentHashMap如何实现线程安全？

ConcurrentHashMap 通过**分段锁优化、CAS 无锁操作、细粒度锁分离、volatile 可见性保证**等多重机制实现线程安全，同时兼顾高并发性能。以下是其核心实现原理的深度解析：

### 一、JDK 1.7：分段锁（Segment）机制
#### 1. 数据结构与锁设计
- **分段存储**：  
  将哈希表划分为 16 个独立的 `Segment`（默认并发度），每个 `Segment` 是一个小型的哈希表，内部包含独立的 `ReentrantLock` 锁。例如，当线程访问不同的 `Segment` 时，可并行操作互不干扰。
- **锁粒度控制**：  
  写入操作（如 `put`）仅需锁定目标 `Segment`，而其他 `Segment` 仍可被其他线程访问。例如，若两个线程分别操作不同的 `Segment`，无需等待锁释放。

#### 2. 线程安全实现
- **分段锁隔离**：  
  每个 `Segment` 内部的哈希表操作（如插入、删除）通过 `ReentrantLock` 保证原子性。例如，插入元素时，线程先获取 `Segment` 的锁，操作完成后释放锁。
- **弱一致性读**：  
  读操作无需加锁，直接通过 `volatile` 修饰的 `HashEntry` 字段获取值。但由于写入可能发生在其他 `Segment`，读取到的值可能不是最新的，属于弱一致性设计。

#### 3. 局限性
- **锁粒度仍较大**：  
  同一 `Segment` 内的所有桶共享一把锁，若多个线程竞争同一 `Segment`，仍可能产生锁竞争。
- **空间利用率低**：  
  `Segment` 数组初始化后不可扩容，默认 16 个 `Segment` 可能导致内存浪费。

### 二、JDK 1.8：CAS + 细粒度锁 + 红黑树
#### 1. 数据结构升级
- **数组 + 链表 + 红黑树**：  
  直接使用 `Node` 数组存储键值对，链表长度超过阈值（默认 8）且数组长度 ≥ 64 时，链表转为红黑树，查询复杂度从 O(n) 降至 O(log n)。
- **节点类型分化**：  
  - `Node`：普通链表节点，`val` 和 `next` 用 `volatile` 修饰，保证可见性。  
  - `TreeBin`：红黑树的包装节点，通过 `synchronized` 控制树结构修改。  
  - `ForwardingNode`：扩容标记节点，指引线程到新数组。

#### 2. 线程安全核心机制
- **CAS 无锁插入**：  
  当目标桶为空时，直接通过 `CAS` 原子性地将新节点插入桶头部。例如：
  ```java
  if (casTabAt(tab, i, null, new Node<K,V>(hash, key, value, null))) break;
  ```
  若 CAS 失败（桶已被其他线程占用），则进入锁同步流程。

- **synchronized 锁头节点**：  
  当桶非空时，对链表或红黑树的头节点加 `synchronized` 锁。例如，插入元素时：
  ```java
  synchronized (f) {
      // 链表或红黑树插入逻辑
  }
  ```
  锁粒度降至单个桶，不同桶的操作完全并行。

- **volatile 可见性保证**：  
  - `Node.val` 和 `Node.next` 用 `volatile` 修饰，确保写线程修改后读线程立即可见。  
  - `table` 数组本身用 `volatile` 修饰，保证扩容时新数组的可见性。

#### 3. 扩容机制优化
- **多线程协作迁移**：  
  当触发扩容时，多个线程可同时迁移数据。每个线程负责部分桶的迁移，通过 `ForwardingNode` 标记已迁移的桶，其他线程遇到标记节点时会协助迁移。
- **无锁化迁移**：  
  迁移过程中，旧数组仍可被读取，新写入的数据会被直接插入新数组。例如，读操作遇到 `ForwardingNode` 时，会自动到新数组查找。

#### 4. 计数与并发控制
- **CounterCell 分散竞争**：  
  `size()` 方法通过 `baseCount`（基础计数）和 `CounterCell` 数组（分散计数）统计元素总数。当多线程更新计数冲突时，将计数分散到 `CounterCell` 中，减少 CAS 重试次数。
- **弱一致性设计**：  
  `size()` 返回的是近似值，因为统计期间可能有并发修改。若需精确值，需遍历所有桶（性能代价高）。

### 三、关键优化点对比
| 特性                | JDK 1.7 分段锁                                                                 | JDK 1.8 CAS + 细粒度锁                                                      |
|---------------------|---------------------------------------------------------------------------------|-----------------------------------------------------------------------------|
| **锁粒度**          | 每个 `Segment` 一把锁，包含多个桶                                              | 每个桶的头节点一把锁，锁粒度更细                                            |
| **写入性能**        | 同一 `Segment` 内的操作串行化                                                  | 不同桶的写入完全并行，同一桶的写入通过 CAS 或 `synchronized` 保证原子性    |
| **读性能**          | 无锁读，但可能读到旧数据                                                      | 无锁读，`volatile` 保证可见性，数据实时性更高                              |
| **扩容机制**        | 每个 `Segment` 独立扩容，全局扩容需遍历所有 `Segment`                           | 多线程协作扩容，迁移期间支持读写                                           |
| **内存利用率**      | `Segment` 数组固定大小，可能浪费空间                                           | 数组按需扩容，空间利用率更高                                                |

### 四、典型场景实现分析
#### 1. put 操作流程
1. **计算哈希值**：通过 `spread(key.hashCode())` 生成哈希，减少冲突。
2. **初始化数组**：首次写入时，通过 CAS 竞争初始化 `table` 数组。
3. **无锁插入**：若目标桶为空，直接 CAS 插入新节点。
4. **处理扩容**：若当前桶为 `ForwardingNode`，协助迁移数据到新数组。
5. **加锁操作**：对桶头节点加 `synchronized` 锁，处理链表或红黑树插入逻辑。
6. **触发扩容**：插入后检查是否需要扩容，多线程协作完成迁移。

#### 2. get 操作流程
1. **计算哈希值**：定位到目标桶。
2. **检查头节点**：若头节点匹配，直接返回值。
3. **处理扩容**：若头节点为 `ForwardingNode`，到新数组查找。
4. **遍历链表/红黑树**：无锁遍历，通过 `volatile` 保证可见性。

### 五、总结
ConcurrentHashMap 的线程安全实现是**锁机制、无锁算法、数据结构优化**的综合产物：
- **JDK 1.7** 通过分段锁实现线程安全，但锁粒度较大，并发性能受限。
- **JDK 1.8** 改用 CAS + `synchronized` 细粒度锁，结合红黑树和多线程扩容，显著提升了并发性能和内存效率。
- **核心优势**：  
  - 写入操作通过 CAS 和 `synchronized` 保证原子性，锁竞争最小化。  
  - 读操作无锁化，`volatile` 确保可见性，避免线程阻塞。  
  - 多线程协作扩容和分散计数机制，减少扩容停顿和竞争热点。

通过这些设计，ConcurrentHashMap 在高并发场景下提供了线程安全的高效哈希表实现，成为 Java 并发编程的核心工具之一。